{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# XAl-ChangeNet Visualization\n",
        "Interactively inspect predictions, Grad-CAM heatmaps, and overlays.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "\n",
        "from models.siamese_unet import SiameseResNet18UNet\n",
        "from scripts.explain import grad_cam as grad_cam_fn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pairs_file = Path('data/xbd/pairs_example.json')  # update to actual manifest\n",
        "ckpt_path = Path('checkpoints/latest.pth')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with pairs_file.open('r', encoding='utf-8') as f:\n",
        "    record = json.load(f)[0]\n",
        "root = pairs_file.parent\n",
        "pre_path = root / record['pre_image']\n",
        "post_path = root / record['post_image']\n",
        "mask_path = root / record['mask']\n",
        "\n",
        "pre_img = np.array(Image.open(pre_path).convert('RGB'))\n",
        "post_img = np.array(Image.open(post_path).convert('RGB'))\n",
        "mask_img = np.array(Image.open(mask_path).convert('L')) / 255.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from albumentations import Compose, Resize, Normalize\n",
        "\n",
        "transform = Compose([Resize(512, 512), Normalize()])\n",
        "pre_tensor = torch.from_numpy(transform(image=pre_img)['image'].transpose(2, 0, 1)).unsqueeze(0).float().to(device)\n",
        "post_tensor = torch.from_numpy(transform(image=post_img)['image'].transpose(2, 0, 1)).unsqueeze(0).float().to(device)\n",
        "mask_tensor = torch.from_numpy(mask_img).unsqueeze(0).unsqueeze(0).float().to(device)\n",
        "\n",
        "model = SiameseResNet18UNet().to(device)\n",
        "ckpt = torch.load(ckpt_path, map_location=device)\n",
        "model.load_state_dict(ckpt['model'])\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    logits = model(pre_tensor, post_tensor)\n",
        "    probs = torch.sigmoid(logits)\n",
        "pred_mask = probs.squeeze().cpu().numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 4, figsize=(18, 6))\n",
        "axes[0].imshow(pre_img); axes[0].set_title('Pre'); axes[0].axis('off')\n",
        "axes[1].imshow(post_img); axes[1].set_title('Post'); axes[1].axis('off')\n",
        "axes[2].imshow(mask_img, cmap='gray'); axes[2].set_title('Ground Truth'); axes[2].axis('off')\n",
        "axes[3].imshow(pred_mask, cmap='magma'); axes[3].set_title('Prediction'); axes[3].axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grad_cam_fn(model, pre_tensor, post_tensor, device, Path('outputs') / 'viz_grad_cam.png', post_img)\n",
        "Image.open(Path('outputs') / 'viz_grad_cam.png')\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
